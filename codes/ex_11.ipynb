{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.909691\n",
      "1 Test accuracy: 0.912191\n",
      "2 Test accuracy: 0.919592\n",
      "3 Test accuracy: 0.925393\n",
      "4 Test accuracy: 0.928893\n",
      "5 Test accuracy: 0.930593\n",
      "6 Test accuracy: 0.932793\n",
      "7 Test accuracy: 0.934893\n",
      "8 Test accuracy: 0.938194\n",
      "9 Test accuracy: 0.940694\n",
      "10 Test accuracy: 0.940194\n",
      "11 Test accuracy: 0.940894\n",
      "12 Test accuracy: 0.940094\n",
      "13 Test accuracy: 0.944494\n",
      "14 Test accuracy: 0.945495\n",
      "15 Test accuracy: 0.945695\n",
      "16 Test accuracy: 0.947895\n",
      "17 Test accuracy: 0.950895\n",
      "18 Test accuracy: 0.949895\n",
      "19 Test accuracy: 0.950795\n",
      "20 Test accuracy: 0.949395\n",
      "21 Test accuracy: 0.948195\n",
      "22 Test accuracy: 0.953295\n",
      "23 Test accuracy: 0.952695\n",
      "24 Test accuracy: 0.953495\n",
      "25 Test accuracy: 0.953195\n",
      "26 Test accuracy: 0.953495\n",
      "27 Test accuracy: 0.955696\n",
      "28 Test accuracy: 0.956696\n",
      "29 Test accuracy: 0.958096\n",
      "30 Test accuracy: 0.956796\n",
      "31 Test accuracy: 0.955296\n",
      "32 Test accuracy: 0.952995\n",
      "33 Test accuracy: 0.956596\n",
      "34 Test accuracy: 0.956196\n",
      "35 Test accuracy: 0.958296\n",
      "36 Test accuracy: 0.957296\n",
      "37 Test accuracy: 0.959596\n",
      "38 Test accuracy: 0.962096\n",
      "39 Test accuracy: 0.958896\n",
      "40 Test accuracy: 0.960196\n",
      "41 Test accuracy: 0.959296\n",
      "42 Test accuracy: 0.959996\n",
      "43 Test accuracy: 0.960896\n",
      "44 Test accuracy: 0.960296\n",
      "45 Test accuracy: 0.960596\n",
      "46 Test accuracy: 0.961596\n",
      "47 Test accuracy: 0.960496\n",
      "48 Test accuracy: 0.961996\n",
      "49 Test accuracy: 0.963696\n",
      "50 Test accuracy: 0.961896\n",
      "51 Test accuracy: 0.961796\n",
      "52 Test accuracy: 0.962496\n",
      "53 Test accuracy: 0.964796\n",
      "54 Test accuracy: 0.963796\n",
      "55 Test accuracy: 0.962896\n",
      "56 Test accuracy: 0.962396\n",
      "57 Test accuracy: 0.965397\n",
      "58 Test accuracy: 0.962796\n",
      "59 Test accuracy: 0.963696\n",
      "60 Test accuracy: 0.962396\n",
      "61 Test accuracy: 0.963196\n",
      "62 Test accuracy: 0.963196\n",
      "63 Test accuracy: 0.964096\n",
      "64 Test accuracy: 0.965597\n",
      "65 Test accuracy: 0.965497\n",
      "66 Test accuracy: 0.963996\n",
      "67 Test accuracy: 0.966297\n",
      "68 Test accuracy: 0.965597\n",
      "69 Test accuracy: 0.967297\n",
      "70 Test accuracy: 0.965497\n",
      "71 Test accuracy: 0.965497\n",
      "72 Test accuracy: 0.966297\n",
      "73 Test accuracy: 0.965297\n",
      "74 Test accuracy: 0.966597\n",
      "75 Test accuracy: 0.967297\n",
      "76 Test accuracy: 0.966597\n",
      "77 Test accuracy: 0.965196\n",
      "78 Test accuracy: 0.965597\n",
      "79 Test accuracy: 0.966397\n",
      "80 Test accuracy: 0.965997\n",
      "81 Test accuracy: 0.964296\n",
      "82 Test accuracy: 0.965697\n",
      "83 Test accuracy: 0.966597\n",
      "84 Test accuracy: 0.965697\n",
      "85 Test accuracy: 0.967397\n",
      "86 Test accuracy: 0.966497\n",
      "87 Test accuracy: 0.966197\n",
      "88 Test accuracy: 0.968297\n",
      "89 Test accuracy: 0.967497\n",
      "90 Test accuracy: 0.966997\n",
      "91 Test accuracy: 0.967797\n",
      "92 Test accuracy: 0.967697\n",
      "93 Test accuracy: 0.967597\n",
      "94 Test accuracy: 0.966997\n",
      "95 Test accuracy: 0.967897\n",
      "96 Test accuracy: 0.968797\n",
      "97 Test accuracy: 0.966497\n",
      "98 Test accuracy: 0.968897\n",
      "99 Test accuracy: 0.967897\n",
      "100 Test accuracy: 0.967197\n",
      "101 Test accuracy: 0.968297\n",
      "102 Test accuracy: 0.967497\n",
      "103 Test accuracy: 0.967697\n",
      "104 Test accuracy: 0.967497\n",
      "105 Test accuracy: 0.969197\n",
      "106 Test accuracy: 0.967397\n",
      "107 Test accuracy: 0.966997\n",
      "108 Test accuracy: 0.968597\n",
      "109 Test accuracy: 0.968097\n",
      "110 Test accuracy: 0.966297\n",
      "111 Test accuracy: 0.968897\n",
      "112 Test accuracy: 0.966897\n",
      "113 Test accuracy: 0.969097\n",
      "114 Test accuracy: 0.967497\n",
      "115 Test accuracy: 0.968997\n",
      "116 Test accuracy: 0.967397\n",
      "117 Test accuracy: 0.969197\n",
      "118 Test accuracy: 0.968797\n",
      "119 Test accuracy: 0.968497\n",
      "120 Test accuracy: 0.967297\n",
      "121 Test accuracy: 0.967897\n",
      "122 Test accuracy: 0.970297\n",
      "123 Test accuracy: 0.969297\n",
      "124 Test accuracy: 0.969397\n",
      "125 Test accuracy: 0.970497\n",
      "126 Test accuracy: 0.969697\n",
      "127 Test accuracy: 0.970097\n",
      "128 Test accuracy: 0.969597\n",
      "129 Test accuracy: 0.967397\n",
      "130 Test accuracy: 0.969597\n",
      "131 Test accuracy: 0.968897\n",
      "132 Test accuracy: 0.969397\n",
      "133 Test accuracy: 0.969497\n",
      "134 Test accuracy: 0.969197\n",
      "135 Test accuracy: 0.970697\n",
      "136 Test accuracy: 0.969297\n",
      "137 Test accuracy: 0.970997\n",
      "138 Test accuracy: 0.969697\n",
      "139 Test accuracy: 0.969397\n",
      "140 Test accuracy: 0.969997\n",
      "141 Test accuracy: 0.968997\n",
      "142 Test accuracy: 0.968497\n",
      "143 Test accuracy: 0.968097\n",
      "144 Test accuracy: 0.969197\n",
      "145 Test accuracy: 0.969797\n",
      "146 Test accuracy: 0.969197\n",
      "147 Test accuracy: 0.970097\n",
      "148 Test accuracy: 0.967997\n",
      "149 Test accuracy: 0.970897\n",
      "150 Test accuracy: 0.970697\n",
      "151 Test accuracy: 0.970897\n",
      "152 Test accuracy: 0.969797\n",
      "153 Test accuracy: 0.971697\n",
      "154 Test accuracy: 0.969497\n",
      "155 Test accuracy: 0.969597\n",
      "156 Test accuracy: 0.969597\n",
      "157 Test accuracy: 0.970197\n",
      "158 Test accuracy: 0.969097\n",
      "159 Test accuracy: 0.971797\n",
      "160 Test accuracy: 0.970897\n",
      "161 Test accuracy: 0.970897\n",
      "162 Test accuracy: 0.970097\n",
      "163 Test accuracy: 0.971697\n",
      "164 Test accuracy: 0.970997\n",
      "165 Test accuracy: 0.971397\n",
      "166 Test accuracy: 0.971697\n",
      "167 Test accuracy: 0.970097\n",
      "168 Test accuracy: 0.970397\n",
      "169 Test accuracy: 0.969697\n",
      "170 Test accuracy: 0.971197\n",
      "171 Test accuracy: 0.971697\n",
      "172 Test accuracy: 0.971197\n",
      "173 Test accuracy: 0.969897\n",
      "174 Test accuracy: 0.970397\n",
      "175 Test accuracy: 0.971197\n",
      "176 Test accuracy: 0.970797\n",
      "177 Test accuracy: 0.971597\n",
      "178 Test accuracy: 0.971197\n",
      "179 Test accuracy: 0.971097\n",
      "180 Test accuracy: 0.968997\n",
      "181 Test accuracy: 0.969297\n",
      "182 Test accuracy: 0.970797\n",
      "183 Test accuracy: 0.971097\n",
      "184 Test accuracy: 0.970097\n",
      "185 Test accuracy: 0.970397\n",
      "186 Test accuracy: 0.970897\n",
      "187 Test accuracy: 0.971597\n",
      "188 Test accuracy: 0.970097\n",
      "189 Test accuracy: 0.970997\n",
      "190 Test accuracy: 0.972097\n",
      "191 Test accuracy: 0.972197\n",
      "192 Test accuracy: 0.969197\n",
      "193 Test accuracy: 0.970897\n",
      "194 Test accuracy: 0.969797\n",
      "195 Test accuracy: 0.971697\n",
      "196 Test accuracy: 0.971597\n",
      "197 Test accuracy: 0.970597\n",
      "198 Test accuracy: 0.969697\n",
      "199 Test accuracy: 0.969997\n",
      "[2 9 7 ..., 6 4 0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load MNIST\n",
    "df_train = pd.read_csv(\"../datasets/mnist_train.csv\")\n",
    "X_train_noScale = df_train.iloc[:].drop(\"5\", axis=1).values\n",
    "y_train = df_train.iloc[:][\"5\"].values.reshape(-1,1)\n",
    "df_test = pd.read_csv(\"../datasets/mnist_test.csv\")\n",
    "X_test = df_test.drop(\"7\", axis=1).values\n",
    "y_test = df_test[\"7\"].values.reshape(-1,1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_noScale)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# initialize\n",
    "tf.reset_default_graph()\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "learning_rate = 0.01\n",
    "n_epochs = 200\n",
    "batch_size = 50\n",
    "dropout_rate = 0.5\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training\")\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
    "\n",
    "# layers\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "    with tf.name_scope(\"hidden1\"):\n",
    "        hidden1 = tf.layers.dense(X_drop, n_hidden1, name=\"hidden1\")\n",
    "        hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "        bn1 = my_batch_norm_layer(hidden1_drop)\n",
    "        bn1_act = tf.nn.elu(bn1)\n",
    "    with tf.name_scope(\"hidden2\"):\n",
    "        hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "        hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "        bn2 = my_batch_norm_layer(hidden2_drop)\n",
    "        bn2_act = tf.nn.elu(bn2)\n",
    "    with tf.name_scope(\"outputs\"):\n",
    "        logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "        logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "# loss function\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=tf.cast(tf.reshape(y,[-1]), tf.int32), logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "# train\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, \n",
    "                                           momentum=0.9, use_nesterov=True)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "# evaluation\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, tf.cast(tf.reshape(y,[-1]), tf.int32), 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "logdir = \"../tf_logs/run-{}/\".format(now)\n",
    "file_writer = tf.summary.FileWriter(logdir, graph=tf.get_default_graph())\n",
    "accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# run\n",
    "init = tf.global_variables_initializer()\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        shuffled_index = np.random.permutation(len(X_train))\n",
    "        X_train, y_train = X_train[shuffled_index], y_train[shuffled_index]\n",
    "        X_train_noScale = X_train_noScale[shuffled_index]\n",
    "        for i in range(len(X_train) // batch_size):\n",
    "            X_batch = X_train[batch_size * i : batch_size * (i+1)]\n",
    "            y_batch = y_train[batch_size * i : batch_size * (i+1)]\n",
    "            sess.run([training_op, extra_update_ops], \n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        file_writer.add_summary(accuracy_summary.eval(feed_dict={X: X_test, y: y_test}), epoch)\n",
    "        print(epoch, \"Test accuracy:\", accuracy_test)\n",
    "    Z = logits.eval(feed_dict={X: X_train[:]})\n",
    "    y_pred = np.argmax(Z, axis=1)\n",
    "    print(y_pred)\n",
    "file_writer.flush()\n",
    "\n",
    "# monitor\n",
    "cl_a, cl_b = 3, 5\n",
    "X_aa = X_train_noScale[(y_train.ravel() == cl_a) & (y_pred == cl_a)]\n",
    "X_ab = X_train_noScale[(y_train.ravel() == cl_a) & (y_pred == cl_b)]\n",
    "X_ba = X_train_noScale[(y_train.ravel() == cl_b) & (y_pred == cl_a)]\n",
    "X_bb = X_train_noScale[(y_train.ravel() == cl_b) & (y_pred == cl_b)]\n",
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap=matplotlib.cm.binary, **options)\n",
    "    plt.axis(\"off\")\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(221);\n",
    "plot_digits(X_aa[:25], images_per_row=5)\n",
    "plt.subplot(222);\n",
    "plot_digits(X_ab[:25], images_per_row=5)\n",
    "plt.subplot(223);\n",
    "plot_digits(X_ba[:25], images_per_row=5)\n",
    "plt.subplot(224);\n",
    "plot_digits(X_bb[:25], images_per_row=5)\n",
    "plt.savefig(\"../plots/ex_11_01.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

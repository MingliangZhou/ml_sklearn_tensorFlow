{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "#from sklearn.datasets import fetch_mldata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# fetch MNIST data: Dosen't work!\n",
    "#mnist = fetch_mldata(\"MNIST original\")\n",
    "\n",
    "# load csv\n",
    "df_train = pd.read_csv(\"../datasets/mnist_train.csv\")\n",
    "df_test = pd.read_csv(\"../datasets/mnist_test.csv\")\n",
    "X_train = df_train.drop(df_train.columns[[0]], axis=1).values\n",
    "y_train = df_train[df_train.columns[[0]]].values.ravel()\n",
    "X_test = df_test.drop(df_test.columns[[0]], axis=1).values\n",
    "y_test = df_test[df_test.columns[[0]]].values.ravel()\n",
    "\n",
    "# plot one example as image\n",
    "some_index = 36000\n",
    "some_digit = X_train[some_index]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.figure()\n",
    "plt.imshow(some_digit_image, cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"../plots/ex_3_01.pdf\")\n",
    "plt.axis(\"on\")\n",
    "\n",
    "# permuatate train set\n",
    "shuffle_index = np.random.permutation(len(y_train))\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n",
    "\n",
    "# SGD for \"5\"\n",
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n",
    "# CV for accuracy\n",
    "sgd_accuracy = cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "# CV for confusion matrix\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "sgd_conMat = confusion_matrix(y_train_5, y_train_pred)\n",
    "\n",
    "# score for each instance\n",
    "y_scores = sgd_clf.decision_function([some_digit])\n",
    "\n",
    "# scores for all\n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")\n",
    "\n",
    "# random forest classifier\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, \n",
    "                                    cv=3, method=\"predict_proba\")\n",
    "y_scores_forest = y_probas_forest[:, -1]\n",
    "\n",
    "# calculate precision and recall as a function of thresholds\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
    "precisions_forest, recalls_forest, thresholds_forest = precision_recall_curve(y_train_5, \n",
    "                                                                              y_scores_forest)\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"center left\")\n",
    "    plt.ylim([0,1])\n",
    "plt.figure()\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.savefig(\"../plots/ex_3_02.pdf\")\n",
    "plt.figure()\n",
    "plt.plot(recalls, precisions, \"b:\", linewidth=2, label=\"SGD\")\n",
    "plt.plot(recalls_forest, precisions_forest, linewidth=2, label=\"Random Forest\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"../plots/ex_3_03.pdf\")\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5, y_scores_forest)\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0,1], [0,1], \"k--\")\n",
    "    plt.axis([0,1,0,1])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, \"b:\", label=\"SGD\")\n",
    "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"../plots/ex_3_04.pdf\")\n",
    "roc_auc_score(y_train_5, y_scores)\n",
    "roc_auc_score(y_train_5, y_scores_forest)\n",
    "\n",
    "# SGD OvA\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "some_digit_scores = sgd_clf.decision_function([some_digit])\n",
    "\n",
    "# SGD forced OvO\n",
    "ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=42))\n",
    "ovo_clf.fit(X_train, y_train)\n",
    "\n",
    "# SGD OvA CV\n",
    "cv_scores = cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "# SGD OvA scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "cv_scores = cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "# error analysis\n",
    "y_train_pred = cross_val_predict(forest_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "# plot confusion matrix\n",
    "plt.figure()\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.savefig(\"../plots/ex_3_05.pdf\")\n",
    "\n",
    "# normalize confusion matrix\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.figure()\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.savefig(\"../plots/ex_3_06.pdf\")\n",
    "\n",
    "# look into \"3\" and \"5\"\n",
    "cl_a, cl_b = 3, 5\n",
    "X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\n",
    "X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
    "X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
    "X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n",
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap=matplotlib.cm.binary, **options)\n",
    "    plt.axis(\"off\")\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(221);\n",
    "plot_digits(X_aa[:25], images_per_row=5)\n",
    "plt.subplot(222);\n",
    "plot_digits(X_ab[:25], images_per_row=5)\n",
    "plt.subplot(223);\n",
    "plot_digits(X_ba[:25], images_per_row=5)\n",
    "plt.subplot(224);\n",
    "plot_digits(X_bb[:25], images_per_row=5)\n",
    "plt.savefig(\"../plots/ex_3_07.pdf\")\n",
    "\n",
    "# multilabel classification\n",
    "y_train_large = (y_train >= 7)\n",
    "y_train_odd = (y_train % 2 == 1)\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)\n",
    "\n",
    "# multioutput-multiclass classification\n",
    "noise = np.random.randint(0, 100, (len(X_train), 784))\n",
    "X_train_mod = X_train + noise\n",
    "noise = np.random.randint(0, 100, (len(X_test), 784))\n",
    "X_test_mod = X_test + noise\n",
    "y_train_mod = X_train\n",
    "y_test_mod = X_test\n",
    "knn_clf.fit(X_train_mod, y_train_mod)\n",
    "clean_digit = knn_clf.predict([X_test_mod[3]])\n",
    "plt.figure()\n",
    "plt.subplot(131)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(X_test_mod[3].reshape(28,28), cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.subplot(132)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(X_test[3].reshape(28,28), cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.subplot(133)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(clean_digit.reshape(28,28), cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.savefig(\"../plots/ex_3_08.pdf\")\n",
    "plt.axis(\"on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "0 Test loss: 1.21194e+06\n",
      "1 Test loss: 1.14687e+06\n",
      "2 Test loss: 1.11145e+06\n",
      "3 Test loss: 1.09178e+06\n",
      "4 Test loss: 1.08046e+06\n",
      "5 Test loss: 1.08656e+06\n",
      "6 Test loss: 1.06501e+06\n",
      "7 Test loss: 1.05894e+06\n",
      "8 Test loss: 1.05732e+06\n",
      "9 Test loss: 1.04913e+06\n",
      "10 Test loss: 1.04312e+06\n",
      "11 Test loss: 1.03864e+06\n",
      "12 Test loss: 1.03879e+06\n",
      "13 Test loss: 1.03511e+06\n",
      "14 Test loss: 1.03448e+06\n",
      "15 Test loss: 1.03292e+06\n",
      "16 Test loss: 1.02475e+06\n",
      "17 Test loss: 1.02383e+06\n",
      "18 Test loss: 1.02182e+06\n",
      "19 Test loss: 1.02596e+06\n",
      "20 Test loss: 1.01785e+06\n",
      "21 Test loss: 1.01786e+06\n",
      "22 Test loss: 1.01929e+06\n",
      "23 Test loss: 1.01468e+06\n",
      "24 Test loss: 1.01246e+06\n",
      "25 Test loss: 1.01049e+06\n",
      "26 Test loss: 1.00877e+06\n",
      "27 Test loss: 1.00946e+06\n",
      "28 Test loss: 1.01155e+06\n",
      "29 Test loss: 1.00889e+06\n",
      "30 Test loss: 1.01154e+06\n",
      "31 Test loss: 1.00841e+06\n",
      "32 Test loss: 1.0032e+06\n",
      "33 Test loss: 1.00534e+06\n",
      "34 Test loss: 1.00251e+06\n",
      "35 Test loss: 1.00478e+06\n",
      "36 Test loss: 1.0027e+06\n",
      "37 Test loss: 999722.0\n",
      "38 Test loss: 1.00055e+06\n",
      "39 Test loss: 1.00157e+06\n",
      "40 Test loss: 1.00053e+06\n",
      "41 Test loss: 995638.0\n",
      "42 Test loss: 996751.0\n",
      "43 Test loss: 997210.0\n",
      "44 Test loss: 998241.0\n",
      "45 Test loss: 995500.0\n",
      "46 Test loss: 997020.0\n",
      "47 Test loss: 997980.0\n",
      "48 Test loss: 994244.0\n",
      "49 Test loss: 991418.0\n",
      "50 Test loss: 993625.0\n",
      "51 Test loss: 991822.0\n",
      "52 Test loss: 994758.0\n",
      "53 Test loss: 990652.0\n",
      "54 Test loss: 992121.0\n",
      "55 Test loss: 991588.0\n",
      "56 Test loss: 993156.0\n",
      "57 Test loss: 996053.0\n",
      "58 Test loss: 994683.0\n",
      "59 Test loss: 990860.0\n",
      "60 Test loss: 990232.0\n",
      "61 Test loss: 993308.0\n",
      "62 Test loss: 994298.0\n",
      "63 Test loss: 994341.0\n",
      "64 Test loss: 996619.0\n",
      "65 Test loss: 988796.0\n",
      "66 Test loss: 988685.0\n",
      "67 Test loss: 986741.0\n",
      "68 Test loss: 987848.0\n",
      "69 Test loss: 986120.0\n",
      "70 Test loss: 987181.0\n",
      "71 Test loss: 989207.0\n",
      "72 Test loss: 985352.0\n",
      "73 Test loss: 992982.0\n",
      "74 Test loss: 983640.0\n",
      "75 Test loss: 987738.0\n",
      "76 Test loss: 987028.0\n",
      "77 Test loss: 984974.0\n",
      "78 Test loss: 983492.0\n",
      "79 Test loss: 985378.0\n",
      "80 Test loss: 986048.0\n",
      "81 Test loss: 983804.0\n",
      "82 Test loss: 980614.0\n",
      "83 Test loss: 982902.0\n",
      "84 Test loss: 982347.0\n",
      "85 Test loss: 986240.0\n",
      "86 Test loss: 982882.0\n",
      "87 Test loss: 986471.0\n",
      "88 Test loss: 980633.0\n",
      "89 Test loss: 984253.0\n",
      "90 Test loss: 984703.0\n",
      "91 Test loss: 982358.0\n",
      "92 Test loss: 981119.0\n",
      "93 Test loss: 982321.0\n",
      "94 Test loss: 982470.0\n",
      "95 Test loss: 982440.0\n",
      "96 Test loss: 981220.0\n",
      "97 Test loss: 979643.0\n",
      "98 Test loss: 981739.0\n",
      "99 Test loss: 982132.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 500\n",
    "n_hidden2 = 500\n",
    "n_hidden3 = 20\n",
    "n_hidden4 = n_hidden2\n",
    "n_hidden5 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "my_dense_layer = partial(tf.layers.dense, activation=tf.nn.elu, \n",
    "                        kernel_initializer=initializer)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "hidden1 = my_dense_layer(X, n_hidden1)\n",
    "hidden2 = my_dense_layer(hidden1, n_hidden2)\n",
    "hidden3_mean = my_dense_layer(hidden2, n_hidden3, activation=None)\n",
    "hidden3_gamma = my_dense_layer(hidden2, n_hidden3, activation=None)\n",
    "noise = tf.random_normal(tf.shape(hidden3_gamma), dtype=tf.float32)\n",
    "hidden3 = hidden3_mean + tf.exp(0.5 * hidden3_gamma) * noise\n",
    "hidden4 = my_dense_layer(hidden3, n_hidden4)\n",
    "hidden5 = my_dense_layer(hidden4, n_hidden5)\n",
    "logits = my_dense_layer(hidden5, n_outputs, activation=None)\n",
    "outputs = tf.sigmoid(logits)\n",
    "\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=logits)\n",
    "reconstruction_loss = tf.reduce_sum(xentropy)\n",
    "latent_loss = 0.5 * tf.reduce_sum(\n",
    "    tf.exp(hidden3_gamma) + tf.square(hidden3_mean) - 1 - hidden3_gamma)\n",
    "loss = reconstruction_loss + latent_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_digits = 60\n",
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        loss_test = loss.eval(feed_dict={X: mnist.test.images})\n",
    "        print(epoch, \"Test loss:\", loss_test)\n",
    "    codings_rnd = np.random.normal(size=[n_digits, n_hidden3])\n",
    "    outputs_val = outputs.eval(feed_dict={hidden3: codings_rnd})\n",
    "    \n",
    "plt.figure()\n",
    "for iteration in range(n_digits):\n",
    "    plt.subplot(n_digits // 10, 10, iteration + 1)\n",
    "    plt.imshow(outputs_val[iteration].reshape(28,28), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "plt.savefig(\"../plots/ex_15_03.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
